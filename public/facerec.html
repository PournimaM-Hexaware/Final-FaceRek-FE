<!doctype html>
<html lang="en">
<!-- <script src="https://webrtc.github.io/adapter/adapter-5.0.4.js" type="text/javascript"></script> -->





<head>
    <link href="assets/css/style-face.css" rel="stylesheet" type="text/css" />
    <link href="assets/css/Newstyle.css" rel="stylesheet" type="text/css" />
    <script src="https://webrtc.github.io/adapter/adapter-5.0.4.js" type="text/javascript"></script>
    <script >
        function alertbar() {
            document.getElementById('startAndStop').click()
        }
    </script>
</head>


<body onload="alertbar()">
    <div>
        <input type="submit" id="startAndStop" class="button" style="display:none" />
    </div>
    <div>
        <div class="row">
            <div class="col-sm col-centered">

                <video id="videoInput" width=320 height=240 style="display:none"></video>
                <canvas id="canvasOutput" width=320 height=240 style="position: relative; left: 570px;border-radius: 100px"></canvas>
                <br>
                <br>
                <br>
            </div>
        </div>


    </div>


    <script src="utils.js" type="text/javascript"></script>
    <script src="utils.js" type="text/javascript"></script>


    <script type="text/javascript">
        let utils = new Utils('errorMessage');
        // utils.loadCode('codeSnippet', 'codeEditor');
        let streaming = false;
        let videoInput = document.getElementById('videoInput');
        let startAndStop = document.getElementById('startAndStop');
        let canvasOutput = document.getElementById('canvasOutput');
        let canvasContext = canvasOutput.getContext('2d');

        startAndStop.addEventListener('click', () => {
            // $('#processalert').html("<div class='alert alert-primary'>"+"<span>"+"  Camera is starting........ ."+"</span>"+"</div>")

            if (!streaming) {
                utils.clearError();
                utils.startCamera('qvga', onVideoStarted, 'videoInput');
            } else {
                utils.stopCamera();
                onVideoStopped();
            }
        });
        let framecount = 0;


        function onVideoStarted() {

            streaming = true;
            startAndStop.innerText = 'Stop';
            videoInput.width = videoInput.videoWidth;
            videoInput.height = videoInput.videoHeight;
            // utils.executeCode('codeEditor');
            let video = document.getElementById('videoInput');
            let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            let dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            let gray = new cv.Mat();
            var cap = new cv.VideoCapture(video);
            let faces = new cv.RectVector();
            let classifier = new cv.CascadeClassifier();
            // load pre-trained classifiers
            classifier.load('haarcascade_frontalface_default.xml');
            const FPS = 30;
            function processVideo() {
                try {
                    if (!streaming) {
                        // clean and stop.
                        src.delete();
                        dst.delete();
                        gray.delete();
                        faces.delete();
                        classifier.delete();
                        return;
                    }
                    let begin = Date.now();
                    // $('#processalert').html("<div class='alert alert-primary'>"+"<span>"+" Please wait !! we are capturing your image."+"</span>"+"</div>")
                    // start processing.
                    cap.read(src);
                    src.copyTo(dst);

                    cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
                    // detect faces.

                    classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
                    // draw faces.
                    //reseting framecount if user is not not stabilized
                    if (faces.size() == 0) { framecount = 0 };
                    if (faces.size() > 1) {

                        console.log("detecting multiple faces");
                        framecount = 0;
                    }
                    //processing each frace
                    for (let i = 0; i < faces.size(); ++i) {
                        let face = faces.get(i);
                        if (faces.size() == 1) {
                            console.log(face.width, face.height);
                            if (face.width > 60) {
                                console.log("tracking this face");
                                console.log("tracking face in frame", framecount++);
                                if (framecount == 10) {
                                    console.log("Taking snap after", framecount);
                                    framecount = 0
                                    // var image =snapshot()
                                    var canvas = document.getElementById("canvasOutput");
                                    var image = canvas.toDataURL("image/png");
                                    // document.getElementById('submitPhoto').click()
                                    console.log(image)

                                    document.getElementById('myImage').value = image
                                    document.getElementById('submitPhoto').click()
                                    console.log(myImage)

                                    onVideoStopped()
                                    // alert("took a snap") 
                                }
                            }
                        }
                        let point1 = new cv.Point(face.x, face.y);
                        let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                        cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
                    }
                    cv.imshow('canvasOutput', dst);
                    var data = cv.imread(canvasOutput)

                    // schedule the next one.
                    let delay = 1000 / FPS - (Date.now() - begin);
                    setTimeout(processVideo, delay);
                } catch (err) {
                    utils.printError(err);
                }
            };
            // schedule the first one.
            setTimeout(processVideo, 0);
        }
        function onVideoStopped() {
            // $('#processalert').html("<div class='alert alert-primary'>"+"<span>"+"  Please wait!!! We are recognizing you ."+"</span>"+"</div>")
            streaming = false;
            canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
            startAndStop.innerText = 'Start';
        }
        utils.loadOpenCv(() => {
            let faceCascadeFile = 'haarcascade_frontalface_default.xml';
            utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
                startAndStop.removeAttribute('disabled');
            });
        });

    </script>

    <div>
        <div class="row">
            <form id="myform" method="post" action="/upload">
                <!-- <input id="mydata" type="hidden" name="mydata" value="" /> -->
                <input id="myImage" type="hidden" name="myImage" value="" />
                <input id="submitPhoto" class="buttonSubmit" style="display:none" type="submit" />
        </div>
        </form>
    </div>

    </div>
</body>

</html>